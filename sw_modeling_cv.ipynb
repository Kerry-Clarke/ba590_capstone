{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-Wise Modeling using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# import packages for Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# import modeling packages \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f70</th>\n",
       "      <th>f71</th>\n",
       "      <th>f72</th>\n",
       "      <th>f73</th>\n",
       "      <th>f74</th>\n",
       "      <th>f75</th>\n",
       "      <th>f76</th>\n",
       "      <th>f77</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-0.01821</th>\n",
       "      <td>-0.010433</td>\n",
       "      <td>-0.018399</td>\n",
       "      <td>-0.018279</td>\n",
       "      <td>-2.896385</td>\n",
       "      <td>-0.024231</td>\n",
       "      <td>-0.02066</td>\n",
       "      <td>4.079933</td>\n",
       "      <td>-1.414801</td>\n",
       "      <td>-3.011022</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.01821</th>\n",
       "      <td>-3.182200</td>\n",
       "      <td>-3.260786</td>\n",
       "      <td>-3.270119</td>\n",
       "      <td>-2.037297</td>\n",
       "      <td>-0.024231</td>\n",
       "      <td>-0.02066</td>\n",
       "      <td>3.366161</td>\n",
       "      <td>-3.683655</td>\n",
       "      <td>-3.011022</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                f0        f1        f2        f3        f4       f5        f6  \\\n",
       "-0.01821 -0.010433 -0.018399 -0.018279 -2.896385 -0.024231 -0.02066  4.079933   \n",
       "-0.01821 -3.182200 -3.260786 -3.270119 -2.037297 -0.024231 -0.02066  3.366161   \n",
       "\n",
       "                f7        f8  f9 ...  f70  f71  f72  f73  f74  f75  f76  f77  \\\n",
       "-0.01821 -1.414801 -3.011022   1 ...    0    0    0    0    0    0    0  9.0   \n",
       "-0.01821 -3.683655 -3.011022   1 ...    0    0    0    0    0    0    0  9.0   \n",
       "\n",
       "          Y1  Y2  \n",
       "-0.01821   0   0  \n",
       "-0.01821   0   0  \n",
       "\n",
       "[2 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in modeling data file\n",
    "cols = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
    "       'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20',\n",
    "       'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30',\n",
    "       'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40',\n",
    "       'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50',\n",
    "       'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60',\n",
    "       'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70',\n",
    "       'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'Y1', 'Y2']\n",
    "\n",
    "df = pd.read_csv('data/modeling.csv', header=0, names=cols)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: Y1 (AACP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Splitting up our data into features and target\n",
    "# for this modeling approach I will only be using 1 target at a time \n",
    "# the first target will be Accept (ACCP)\n",
    "X = df.iloc[:, :-2] # Features\n",
    "Y = df.Y1 # Target\n",
    "\n",
    "# import the RandomOverSampler package from imblearn \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# define the model\n",
    "ros = RandomOverSampler(random_state=2019)\n",
    "\n",
    "# fit the training data only to the RandomOverSampler model\n",
    "# this will help address the imbalanced nature of the target variable \n",
    "X_resample, Y_resample = ros.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:LogisticRegression, F1 Score: mean=0.93905, var=0.00001\n",
      "Model:DecisionTreeClassifier, F1 Score: mean=0.95268, var=0.00013\n",
      "Model:KNeighborsClassifier, F1 Score: mean=0.92529, var=0.00003\n",
      "Model:SVC, F1 Score: mean=0.94224, var=0.00001\n",
      "Model:AdaBoostClassifier, F1 Score: mean=0.94708, var=0.00001\n",
      "Model:Random Forest, F1 Score: mean=0.96112, var=0.00004\n",
      "Model:LogisticRegression, AUC Score: mean=0.98279, var=0.00000\n",
      "Model:DecisionTreeClassifier, AUC Score: mean=0.95960, var=0.00014\n",
      "Model:KNeighborsClassifier, AUC Score: mean=0.96979, var=0.00002\n",
      "Model:SVC, AUC Score: mean=0.97833, var=0.00000\n",
      "Model:AdaBoostClassifier, AUC Score: mean=0.98633, var=0.00000\n",
      "Model:XGBoost, AUC Score: mean=0.98802, var=0.00000\n",
      "Model:Random Forest, AUC Score: mean=0.98964, var=0.00001\n"
     ]
    }
   ],
   "source": [
    "# save features and targets as the X_resample and Y_resample variables \n",
    "features, targets = X_resample, Y_resample\n",
    "\n",
    "# define an empty list that the following models will feed into\n",
    "models = []\n",
    "\n",
    "# append the list with all the desired models \n",
    "\n",
    "models.append(('LogisticRegression', LogisticRegression(solver='liblinear', random_state=2019)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=2019)))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "models.append(('SVC', SVC(kernel='rbf',gamma='auto',random_state=2019)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state=2019)))\n",
    "models.append(('XGBoost', xgb.XGBClassifier(n_estimators=100, random_state=2019)))\n",
    "models.append(('Random Forest', RandomForestClassifier(n_estimators=100, random_state=2019)))\n",
    "\n",
    "# use Cross Validation in the model with a 'stratify' option using the StratifiedKFolds package from sklearn\n",
    "# specifiy that the scoring method is F1 \n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=2019)\n",
    "for name, model in models:\n",
    "    score = cross_val_score(model, features, targets, cv=cv, scoring='f1')\n",
    "    print(\"Model:{0}, F1 Score: mean={1:0.5f}, var={2:0.5f}\".format(name, score.mean(), score.var()))\n",
    "    \n",
    "    \n",
    "# Same as above but the scoring option has beeen changed to AUC\n",
    "cv1 = StratifiedKFold(n_splits=10, shuffle=True, random_state=2019)\n",
    "for name, model in models:\n",
    "    score = cross_val_score(model, features, targets, cv=cv1, scoring='roc_auc')\n",
    "    print(\"Model:{0}, AUC Score: mean={1:0.5f}, var={2:0.5f}\".format(name, score.mean(), score.var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9422998845235453\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=2019)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=2019)\n",
    "score = cross_val_score(dt, features, targets, cv=cv, scoring='f1')\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-db2838d05600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# define the feature importance variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_imp_accp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeature_imp_accp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfeature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mfeature_importances_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \"\"\"\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_feature_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "# define the feature importance variable \n",
    "feature_imp_accp = pd.Series(dt.feature_importances_,index=df.iloc[:,:-2].columns).sort_values(ascending=False)\n",
    "\n",
    "# print the results \n",
    "feature_imp_accp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: Y2 (CONF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign the target to Y2\n",
    "X = df.iloc[:, :-2] # Features\n",
    "Y = df.Y2 # Target\n",
    "\n",
    "# import the RandomOverSampler package from imblearn \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# define the model\n",
    "ros = RandomOverSampler(random_state=2019)\n",
    "\n",
    "# fit the training data only to the RandomOverSampler model\n",
    "# this will help address the imbalanced nature of the target variable \n",
    "X_resample, Y_resample = ros.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:LogisticRegression, F1 Score: mean=0.68019, var=0.00002\n",
      "Model:DecisionTreeClassifier, F1 Score: mean=0.94230, var=0.00001\n",
      "Model:KNeighborsClassifier, F1 Score: mean=0.87646, var=0.00001\n",
      "Model:AdaBoostClassifier, F1 Score: mean=0.69346, var=0.00003\n",
      "Model:XGBoost, F1 Score: mean=0.71162, var=0.00002\n",
      "Model:Random Forest, F1 Score: mean=0.96954, var=0.00000\n",
      "Model:LogisticRegression, AUC Score: mean=0.71848, var=0.00003\n",
      "Model:DecisionTreeClassifier, AUC Score: mean=0.94746, var=0.00001\n",
      "Model:KNeighborsClassifier, AUC Score: mean=0.93654, var=0.00001\n",
      "Model:AdaBoostClassifier, AUC Score: mean=0.72858, var=0.00006\n",
      "Model:XGBoost, AUC Score: mean=0.75494, var=0.00004\n",
      "Model:Random Forest, AUC Score: mean=0.99593, var=0.00000\n"
     ]
    }
   ],
   "source": [
    "# save features and targets as the X_resample and Y_resample variables \n",
    "features, targets = X_resample, Y_resample\n",
    "\n",
    "# define an empty list that the following models will feed into\n",
    "models = []\n",
    "\n",
    "# append the list with all the desired models \n",
    "\n",
    "models.append(('LogisticRegression', LogisticRegression(solver='liblinear', random_state=2019)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=2019)))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "#models.append(('SVC', SVC(kernel='rbf',gamma='auto',random_state=2019)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state=2019)))\n",
    "models.append(('XGBoost', xgb.XGBClassifier(n_estimators=100, random_state=2019)))\n",
    "models.append(('Random Forest', RandomForestClassifier(n_estimators=100, random_state=2019)))\n",
    "\n",
    "# use Cross Validation in the model with a 'stratify' option using the StratifiedKFolds package from sklearn\n",
    "# specifiy that the scoring method is F1 \n",
    "cv2 = StratifiedKFold(n_splits=10, shuffle=True, random_state=2019)\n",
    "for name, model in models:\n",
    "    score = cross_val_score(model, features, targets, cv=cv2, scoring='f1')\n",
    "    print(\"Model:{0}, F1 Score: mean={1:0.5f}, var={2:0.5f}\".format(name, score.mean(), score.var()))\n",
    "    \n",
    "    \n",
    "# Same as above but the scoring option has beeen changed to AUC\n",
    "cv3 = StratifiedKFold(n_splits=10, shuffle=True, random_state=2019)\n",
    "for name, model in models:\n",
    "    score = cross_val_score(model, features, targets, cv=cv3, scoring='roc_auc')\n",
    "    print(\"Model:{0}, AUC Score: mean={1:0.5f}, var={2:0.5f}\".format(name, score.mean(), score.var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
